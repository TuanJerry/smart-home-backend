from scipy.io.wavfile import write
from sklearn.metrics.pairwise import cosine_similarity
from app.utils import AImodel, model_ready

import sounddevice as sd
import soundfile as sf
import numpy as np
import threading
import torch
import time
import os
import re

# M·∫´u c√¢u l·ªánh v√† intent t∆∞∆°ng ·ª©ng
intent_templates = {
    "b·∫≠t ƒë√®n": "TURN_ON_LIGHT",
    # "m·ªü ƒë√®n": "TURN_ON_LIGHT",
    # "ƒë√®n b·∫≠t": "TURN_ON_LIGHT",
    "kh√¥ng t·∫Øt ƒë√®n": "TURN_ON_LIGHT",
    # "ƒë√®n s√°ng": "TURN_ON_LIGHT",
    "t·ªëi qu√°": "TURN_ON_LIGHT",
    "kh√¥ng th·∫•y g√¨": "TURN_ON_LIGHT",
    "t·ªëi nh∆∞ m·ª±c": "TURN_ON_LIGHT",
    "t·ªëi r·ªìi": "TURN_ON_LIGHT",
    # "ƒë√®n t·∫Øt": "TURN_OFF_LIGHT",
    "t·∫Øt ƒë√®n": "TURN_OFF_LIGHT",
    # "ƒë√®n kh√¥ng s√°ng": "TURN_OFF_LIGHT",
    # "ƒë√®n kh√¥ng m·ªü": "TURN_OFF_LIGHT",
    "kh√¥ng b·∫≠t ƒë√®n": "TURN_OFF_LIGHT",
    "s√°ng qu√°": "TURN_OFF_LIGHT",
    "ch√≥i qu√°": "TURN_OFF_LIGHT",
    "s√°ng r·ªìi": "TURN_OFF_LIGHT",

    "b·∫≠t qu·∫°t": "TURN_ON_FAN",
    "t·∫Øt qu·∫°t": "TURN_OFF_FAN",
    # "qu·∫°t ch·∫°y": "TURN_ON_FAN",
    "qu·∫°t kh√¥ng ng·ª´ng": "TURN_ON_FAN",
    "n√≥ng qu√°": "TURN_ON_FAN",
    "h·∫ßm qu√°": "TURN_ON_FAN",
    # "m·ªü qu·∫°t": "TURN_ON_FAN",
    # "qu·∫°t m·ªü": "TURN_ON_FAN",
    "qu·∫°t ng·ª´ng": "TURN_OFF_FAN",
    # "qu·∫°t kh√¥ng ch·∫°y": "TURN_OFF_FAN",
    "kh√¥ng t·∫Øt qu·∫°t": "TURN_ON_FAN",
    # "qu·∫°t kh√¥ng m·ªü": "TURN_OFF_FAN",
    "kh√¥ng b·∫≠t qu·∫°t": "TURN_OFF_FAN",
    "l·∫°nh qu√°": "TURN_OFF_FAN",
    # "r√©t qu√°": "TURN_OFF_FAN",

    "m·ªü c·ª≠a": "OPEN_DOOR",
    "m·ªü kh√≥a c·ª≠a": "OPEN_DOOR",
    "t·∫Øt kh√≥a c·ª≠a": "OPEN_DOOR",
    # "c·ª≠a m·ªü": "OPEN_DOOR",
    "kh√¥ng ƒë√≥ng c·ª≠a": "OPEN_DOOR",
    # "t√¥i chu·∫©n b·ªã ra ngo√†i": "OPEN_DOOR",
    "t√¥i s·∫Øp ra ngo√†i": "OPEN_DOOR",
    "t√¥i chu·∫©n b·ªã v·ªÅ nh√†": "OPEN_DOOR",
    # "t√¥i ƒëi ra ngo√†i": "OPEN_DOOR",
    "ƒë√≥ng c·ª≠a": "CLOSE_DOOR",
    "kh√≥a c·ª≠a": "CLOSE_DOOR",
    # "c·ª≠a ƒë√≥ng": "CLOSE_DOOR",
    "kh√¥ng m·ªü c·ª≠a": "CLOSE_DOOR",
    "t√¥i ra ngo√†i r·ªìi": "CLOSE_DOOR",
    # "t√¥i v·ªÅ nh√† r·ªìi": "CLOSE_DOOR",
    "t√¥i v√¥ nh√† r·ªìi": "CLOSE_DOOR",
    # "t√¥i v·ªÅ r·ªìi": "CLOSE_DOOR",

    "b·∫≠t ch·∫ø ƒë·ªô ban ƒë√™m": "TURN_ON_LIGHT_AND_TURN_ON_FAN_AND_CLOSE_DOOR",
    "t·∫Øt ch·∫ø ƒë·ªô ban ƒë√™m": "TURN_OFF_LIGHT_AND_TURN_OFF_FAN_AND_OPEN_DOOR",
    "b·∫≠t ch·∫ø ƒë·ªô an ninh": "CLOSE_DOOR_AND_TURN_ON_FACE_DETECTION",
    "t·∫Øt ch·∫ø ƒë·ªô an ninh": "OPEN_DOOR_AND_TURN_OFF_FACE_DETECTION",
    "b·∫≠t t·∫•t c·∫£ thi·∫øt b·ªã": "TURN_ON_LIGHT_AND_TURN_ON_FAN_AND_OPEN_DOOR",
    "t·∫Øt t·∫•t c·∫£ thi·∫øt b·ªã": "TURN_OFF_LIGHT_AND_TURN_OFF_FAN_AND_CLOSE_DOOR",
}

class VoiceRecordingService:
    def __init__(self):
        os.makedirs("app/voices", exist_ok=True)
        # L∆∞u s·∫µn embeddings c·ªßa intent m·∫´u
        self.template_embeddings = None

    async def init_embeddings(self, intent_templates: dict):
        if self.template_embeddings is None:
            self.template_embeddings = {
                k: await self.get_sentence_embedding(k)
                for k in intent_templates.keys()
            }

    # Voice recording service for handling audio input into strings
    def countdown_timer(self, duration):
        for remaining in range(duration, 0, -1):
            print(f"‚è≥ C√≤n l·∫°i: {remaining} gi√¢y", end='\r')
            time.sleep(1)
        print("‚è≥ C√≤n l·∫°i: 0 gi√¢y         ")

    def is_valid_audio(self, file_path, min_rms=0.01, max_silence_ratio=0.9):
        audio, sr = sf.read(file_path)
        if audio.ndim > 1:
            audio = np.mean(audio, axis=1)  # Convert to mono

        rms = np.sqrt(np.mean(audio**2))
        if rms < min_rms:
            print("‚ö†Ô∏è √Çm l∆∞·ª£ng qu√° nh·ªè.")
            return False

        frame_len = 2048
        hop_len = 512
        frame_count = 1 + (len(audio) - frame_len) // hop_len
        energies = np.array([
            np.sqrt(np.mean(audio[i*hop_len:i*hop_len+frame_len]**2))
            for i in range(frame_count)
        ])
        silence_ratio = np.mean(energies < min_rms)

        if silence_ratio > max_silence_ratio:
            print("‚ö†Ô∏è Qu√° nhi·ªÅu kho·∫£ng im l·∫∑ng.")
            return False

        return True

    def preprocess_audio(self, file_path, processed_path="app/voices/processed.wav", target_sr=16000):
        audio, sr = sf.read(file_path)
        if audio.ndim > 1:
            audio = np.mean(audio, axis=1)  # Convert to mono

        if sr != target_sr:
            import librosa
            audio = librosa.resample(audio, orig_sr=sr, target_sr=target_sr)
            sr = target_sr

        # Chu·∫©n h√≥a
        audio = audio / np.max(np.abs(audio))

        sf.write(processed_path, audio, sr, subtype='PCM_16')
        print("‚úÖ ƒê√£ ti·ªÅn x·ª≠ l√Ω √¢m thanh.")
        return processed_path

    def record_audio(self, filename="app/voices/recorded.wav", duration=3, fs=16000):
        print(f"üéôÔ∏è ƒêang ghi √¢m trong {duration} gi√¢y...")

        timer_thread = threading.Thread(target=self.countdown_timer, args=(duration,))
        timer_thread.start()

        recording = sd.rec(int(duration * fs), samplerate=fs, channels=1, dtype='int16')
        sd.wait()
        timer_thread.join()

        write(filename, fs, recording)
        print("‚úÖ Ghi √¢m xong.")

        start_time = time.time()

        # return filename, start_time

        # Ki·ªÉm tra ch·∫•t l∆∞·ª£ng
        if self.is_valid_audio(filename):
            return self.preprocess_audio(filename), start_time
            # return filename, start_time
        else:
            print("‚ùå √Çm thanh kh√¥ng ƒë·∫°t y√™u c·∫ßu. H√£y th·ª≠ l·∫°i.")
            return None, start_time
        
    # Text from audio handling by NLP model
    async def get_sentence_embedding(self, sentence: str) -> torch.Tensor:
        """Chuy·ªÉn c√¢u th√†nh vector embedding trung b√¨nh (mean pooling)."""
        await model_ready.wait()  # ‚úÖ Ch·ªù m√¥ h√¨nh s·∫µn s√†ng
        input_ids = AImodel.tokenizer.encode(sentence, return_tensors='pt')
        with torch.no_grad():
            outputs = AImodel.nlp_model(input_ids)
            last_hidden_state = outputs[0]  # (1, seq_len, hidden_dim)
            sentence_embedding = last_hidden_state.mean(dim=1)  # (1, hidden_dim)
        return sentence_embedding.squeeze(0)  # (hidden_dim,)

    # # H√†m embedding
    # def get_sentence_embedding(sentence: str) -> torch.Tensor:
    #     input_ids = AImodel.tokenizer.encode(sentence, return_tensors='pt')
    #     with torch.no_grad():
    #         outputs = AImodel.nlp_model(input_ids)
    #         last_hidden_state = outputs[0]
    #         sentence_embedding = last_hidden_state.mean(dim=1)
    #     return sentence_embedding.squeeze(0)

    # Tr√≠ch xu·∫•t ƒëi·ªÅu ki·ªán s·ªë (temperature, humidity, time)
    def extract_numeric_condition(self, sentence: str) -> dict:
        patterns = [
            # Nhi·ªát ƒë·ªô
            (
                r"(tr·ªùi)? (nhi·ªát[\s_]*ƒë·ªô|n√≥ng|l·∫°nh).*?(((\d+)\s*(ƒë·ªô[\s_]*[CcKk]?|¬∞[CcKk]?)?)|(th·∫•p|cao))?",
                "temperature"
            ),
            # ƒê·ªô ·∫©m
            (
                r"(tr·ªùi)? (ƒë·ªô[\s_]*·∫©m).*?((\d+)\s*(ph·∫ßn[\s_]*trƒÉm|%)?)?",
                "humidity"
            ),
            # √Ånh s√°ng
            (
                r"(tr·ªùi|bu·ªïi)?\s*\w*\s*(t·ªëi|s√°ng)",
                "light"
            ),
            # Qu·∫°t
            (
                r"(m·ª©c|t·ªëc ƒë·ªô).*?((\d+)\s*(ph·∫ßn[\s_]*trƒÉm|%))|((nhanh|ch·∫≠m|v·ª´a|th∆∞·ªùng|m·∫°nh|y·∫øu|th·∫•p|cao)| \s* \w*)",
                "fan"
            ),
            # Th·ªùi gian: gi·ªù, ph√∫t, gi√¢y (c√≥ th·ªÉ c√≥ ho·∫∑c kh√¥ng)
            (
                r"(l√∫c|sau|tr∆∞·ªõc).*?(?P<hour>\d+)\s*(gi·ªù|h|g)?(?:\s*(?P<minute>\d+)\s*(ph√∫t|p|m))?(?:\s*(?P<second>\d+)\s*(gi√¢y|s))?",
                "time"
            )
        ]

        for pattern, sensor in patterns:
            match = re.search(pattern, sentence)
            if match:
                # X√°c ƒë·ªãnh to√°n t·ª≠ logic
                op = "="
                if any(kw in sentence for kw in ["tr√™n", "sau", "n√≥ng", "nhi·ªÅu h∆°n"]):
                    op = ">"
                elif any(kw in sentence for kw in ["d∆∞·ªõi", "tr∆∞·ªõc", "l·∫°nh", "√≠t h∆°n"]):
                    op = "<"

                if sensor == "time":
                    hour = int(match.group("hour")) if match.group("hour") else 0
                    minute = int(match.group("minute")) if match.group("minute") else 0
                    second = int(match.group("second")) if match.group("second") else 0
                    return {
                        "sensor": "time",
                        "op": op,
                        "value": {
                            "hour": hour,
                            "minute": minute,
                            "second": second
                        },
                        "unit": "time"
                    }
                if len(match.groups()) < 2:
                    if sensor == "temperature":
                        if "n√≥ng" in sentence:
                            op = ">"
                            val = 30
                        elif "l·∫°nh" in sentence:
                            op = "<"
                            val = 20
                    elif sensor == "humidity":
                        if "·∫©m" in sentence:
                            op = ">"
                            val = 70
                        elif "kh√¥" in sentence:
                            op = "<"
                            val = 30
                if sensor == "temperature":
                    if "th·∫•p" in match.group(2):
                        op = "<"
                        val = 20
                    elif "cao" in match.group(2):
                        op = ">"
                        val = 30
                elif sensor == "light":
                    if "t·ªëi" in sentence:
                        op = "<"
                        val = 20
                    elif "s√°ng" in sentence:
                        op = ">"
                        val = 30
                elif sensor == "fan":
                    if any(kw in sentence for kw in ["nhanh", "m·∫°nh", "cao"]):
                        op = "="
                        val = 100
                    elif any(kw in sentence for kw in ["ch·∫≠m", "y·∫øu", "th·∫•p"]):
                        op = "="
                        val = 30
                    elif any(kw in sentence for kw in ["v·ª´a", "th∆∞·ªùng"]):
                        op = "="
                        val = 70

                val = int(match.group(2))
                unit = match.group(3) if match.lastindex and match.lastindex >= 3 else ""

                if sensor == "temperature":
                    if unit.lower() in ["ƒë·ªô_k", "ƒë·ªô k", "¬∞k"]:
                        val -= 273
                    unit = "¬∞C"
                elif sensor == "humidity":
                    unit = "%"
                elif sensor == "light":
                    unit = "lux"
                elif sensor == "fan":
                    unit = "%"
                return {
                    "sensor": sensor,
                    "op": op,
                    "value": val,
                    "unit": unit.strip() if unit else ""
                }

        return None

    async def nlp_pipeline(self, sentence: str) -> dict:
        await self.init_embeddings(intent_templates=intent_templates)
        condition = self.extract_numeric_condition(sentence)
        sentence_wo_condition = re.sub(r"khi .*|n·∫øu .*|l√∫c .*|qu·∫°t .*", "", sentence).strip()

        emb = (await self.get_sentence_embedding(sentence_wo_condition)).unsqueeze(0)
        sims = {}
        for template, template_emb in self.template_embeddings.items():
            template_emb = template_emb.unsqueeze(0)
            sim = cosine_similarity(emb, template_emb)[0][0]
            sims[template] = sim
        best_template = max(sims, key=sims.get)

        return {
            "sentence": sentence,
            "intent": intent_templates[best_template],
            "matched_template": best_template,
            "similarity": float(sims[best_template]),
            "condition": condition
        }

voice_service = VoiceRecordingService()