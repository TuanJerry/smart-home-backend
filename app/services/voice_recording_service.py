from scipy.io.wavfile import write
from sklearn.metrics.pairwise import cosine_similarity
from app.utils import AImodel, model_ready

import sounddevice as sd
import soundfile as sf
import numpy as np
import threading
import torch
import time
import os
import re

# M·∫´u c√¢u l·ªánh v√† intent t∆∞∆°ng ·ª©ng
intent_templates = {
    "b·∫≠t ƒë√®n": "TURN_ON_LIGHT",
    # "m·ªü ƒë√®n": "TURN_ON_LIGHT",
    # "ƒë√®n b·∫≠t": "TURN_ON_LIGHT",
    "kh√¥ng t·∫Øt ƒë√®n": "TURN_ON_LIGHT",
    # "ƒë√®n s√°ng": "TURN_ON_LIGHT",
    "t·ªëi qu√°": "TURN_ON_LIGHT",
    "kh√¥ng th·∫•y g√¨": "TURN_ON_LIGHT",
    "t·ªëi nh∆∞ m·ª±c": "TURN_ON_LIGHT",
    "t·ªëi r·ªìi": "TURN_ON_LIGHT",
    # "ƒë√®n t·∫Øt": "TURN_OFF_LIGHT",
    "t·∫Øt ƒë√®n": "TURN_OFF_LIGHT",
    # "ƒë√®n kh√¥ng s√°ng": "TURN_OFF_LIGHT",
    # "ƒë√®n kh√¥ng m·ªü": "TURN_OFF_LIGHT",
    "kh√¥ng b·∫≠t ƒë√®n": "TURN_OFF_LIGHT",
    "s√°ng qu√°": "TURN_OFF_LIGHT",
    "ch√≥i qu√°": "TURN_OFF_LIGHT",
    "s√°ng r·ªìi": "TURN_OFF_LIGHT",

    "b·∫≠t qu·∫°t": "TURN_ON_FAN",
    "t·∫Øt qu·∫°t": "TURN_OFF_FAN",
    # "qu·∫°t ch·∫°y": "TURN_ON_FAN",
    "qu·∫°t kh√¥ng ng·ª´ng": "TURN_ON_FAN",
    "n√≥ng qu√°": "TURN_ON_FAN",
    "h·∫ßm qu√°": "TURN_ON_FAN",
    # "m·ªü qu·∫°t": "TURN_ON_FAN",
    # "qu·∫°t m·ªü": "TURN_ON_FAN",
    "qu·∫°t ng·ª´ng": "TURN_OFF_FAN",
    # "qu·∫°t kh√¥ng ch·∫°y": "TURN_OFF_FAN",
    "kh√¥ng t·∫Øt qu·∫°t": "TURN_ON_FAN",
    # "qu·∫°t kh√¥ng m·ªü": "TURN_OFF_FAN",
    "kh√¥ng b·∫≠t qu·∫°t": "TURN_OFF_FAN",
    "l·∫°nh qu√°": "TURN_OFF_FAN",
    # "r√©t qu√°": "TURN_OFF_FAN",

    "m·ªü c·ª≠a": "OPEN_DOOR",
    "m·ªü kh√≥a c·ª≠a": "OPEN_DOOR",
    "t·∫Øt kh√≥a c·ª≠a": "OPEN_DOOR",
    # "c·ª≠a m·ªü": "OPEN_DOOR",
    "kh√¥ng ƒë√≥ng c·ª≠a": "OPEN_DOOR",
    # "t√¥i chu·∫©n b·ªã ra ngo√†i": "OPEN_DOOR",
    "t√¥i s·∫Øp ra ngo√†i": "OPEN_DOOR",
    "t√¥i chu·∫©n b·ªã v·ªÅ nh√†": "OPEN_DOOR",
    # "t√¥i ƒëi ra ngo√†i": "OPEN_DOOR",
    "ƒë√≥ng c·ª≠a": "CLOSE_DOOR",
    "kh√≥a c·ª≠a": "CLOSE_DOOR",
    # "c·ª≠a ƒë√≥ng": "CLOSE_DOOR",
    "kh√¥ng m·ªü c·ª≠a": "CLOSE_DOOR",
    "t√¥i ra ngo√†i r·ªìi": "CLOSE_DOOR",
    # "t√¥i v·ªÅ nh√† r·ªìi": "CLOSE_DOOR",
    "t√¥i v√¥ nh√† r·ªìi": "CLOSE_DOOR",
    # "t√¥i v·ªÅ r·ªìi": "CLOSE_DOOR",

    "b·∫≠t ch·∫ø ƒë·ªô ban ƒë√™m": "TURN_ON_LIGHT_AND_TURN_ON_FAN_AND_CLOSE_DOOR",
    "t·∫Øt ch·∫ø ƒë·ªô ban ƒë√™m": "TURN_OFF_LIGHT_AND_TURN_OFF_FAN_AND_OPEN_DOOR",
    "b·∫≠t ch·∫ø ƒë·ªô an ninh": "CLOSE_DOOR_AND_TURN_ON_FACE_DETECTION",
    "t·∫Øt ch·∫ø ƒë·ªô an ninh": "OPEN_DOOR_AND_TURN_OFF_FACE_DETECTION",
    "b·∫≠t t·∫•t c·∫£ thi·∫øt b·ªã": "TURN_ON_LIGHT_AND_TURN_ON_FAN_AND_OPEN_DOOR",
    "t·∫Øt t·∫•t c·∫£ thi·∫øt b·ªã": "TURN_OFF_LIGHT_AND_TURN_OFF_FAN_AND_CLOSE_DOOR",
}

class VoiceRecordingService:
    def __init__(self):
        os.makedirs("app/voices", exist_ok=True)
        # L∆∞u s·∫µn embeddings c·ªßa intent m·∫´u
        self.template_embeddings = None

    async def init_embeddings(self, intent_templates: dict):
        if self.template_embeddings is None:
            self.template_embeddings = {
                k: await self.get_sentence_embedding(k)
                for k in intent_templates.keys()
            }

    # Voice recording service for handling audio input into strings
    def countdown_timer(self, duration):
        for remaining in range(duration, 0, -1):
            print(f"‚è≥ C√≤n l·∫°i: {remaining} gi√¢y", end='\r')
            time.sleep(1)
        print("‚è≥ C√≤n l·∫°i: 0 gi√¢y         ")

    def is_valid_audio(self, file_path, min_rms=0.01, max_silence_ratio=0.9):
        audio, sr = sf.read(file_path)
        if audio.ndim > 1:
            audio = np.mean(audio, axis=1)  # Convert to mono

        rms = np.sqrt(np.mean(audio**2))
        if rms < min_rms:
            print("‚ö†Ô∏è √Çm l∆∞·ª£ng qu√° nh·ªè.")
            return False

        frame_len = 2048
        hop_len = 512
        frame_count = 1 + (len(audio) - frame_len) // hop_len
        energies = np.array([
            np.sqrt(np.mean(audio[i*hop_len:i*hop_len+frame_len]**2))
            for i in range(frame_count)
        ])
        silence_ratio = np.mean(energies < min_rms)

        if silence_ratio > max_silence_ratio:
            print("‚ö†Ô∏è Qu√° nhi·ªÅu kho·∫£ng im l·∫∑ng.")
            return False

        return True

    def preprocess_audio(self, file_path, processed_path="app/voices/processed.wav", target_sr=16000):
        audio, sr = sf.read(file_path)
        if audio.ndim > 1:
            audio = np.mean(audio, axis=1)  # Convert to mono

        if sr != target_sr:
            import librosa
            audio = librosa.resample(audio, orig_sr=sr, target_sr=target_sr)
            sr = target_sr

        # Chu·∫©n h√≥a
        audio = audio / np.max(np.abs(audio))

        sf.write(processed_path, audio, sr, subtype='PCM_16')
        print("‚úÖ ƒê√£ ti·ªÅn x·ª≠ l√Ω √¢m thanh.")
        return processed_path

    def record_audio(self, filename="app/voices/recorded.wav", duration=3, fs=16000):
        print(f"üéôÔ∏è ƒêang ghi √¢m trong {duration} gi√¢y...")

        timer_thread = threading.Thread(target=self.countdown_timer, args=(duration,))
        timer_thread.start()

        recording = sd.rec(int(duration * fs), samplerate=fs, channels=1, dtype='int16')
        sd.wait()
        timer_thread.join()

        write(filename, fs, recording)
        print("‚úÖ Ghi √¢m xong.")

        start_time = time.time()

        # return filename, start_time

        # Ki·ªÉm tra ch·∫•t l∆∞·ª£ng
        if self.is_valid_audio(filename):
            return self.preprocess_audio(filename), start_time
            # return filename, start_time
        else:
            print("‚ùå √Çm thanh kh√¥ng ƒë·∫°t y√™u c·∫ßu. H√£y th·ª≠ l·∫°i.")
            return None, start_time
        
    # Text from audio handling by NLP model
    async def get_sentence_embedding(self, sentence: str) -> torch.Tensor:
        """Chuy·ªÉn c√¢u th√†nh vector embedding trung b√¨nh (mean pooling)."""
        await model_ready.wait()  # ‚úÖ Ch·ªù m√¥ h√¨nh s·∫µn s√†ng
        input_ids = AImodel.tokenizer.encode(sentence, return_tensors='pt')
        with torch.no_grad():
            outputs = AImodel.nlp_model(input_ids)
            last_hidden_state = outputs[0]  # (1, seq_len, hidden_dim)
            sentence_embedding = last_hidden_state.mean(dim=1)  # (1, hidden_dim)
        return sentence_embedding.squeeze(0)  # (hidden_dim,)

    # # H√†m embedding
    # def get_sentence_embedding(sentence: str) -> torch.Tensor:
    #     input_ids = AImodel.tokenizer.encode(sentence, return_tensors='pt')
    #     with torch.no_grad():
    #         outputs = AImodel.nlp_model(input_ids)
    #         last_hidden_state = outputs[0]
    #         sentence_embedding = last_hidden_state.mean(dim=1)
    #     return sentence_embedding.squeeze(0)

    # Tr√≠ch xu·∫•t ƒëi·ªÅu ki·ªán s·ªë (temperature, humidity, time)
    def extract_numeric_condition(self, sentence: str) -> dict:
        patterns = [
           # Nhi·ªát ƒë·ªô
            (# vd: nhi·ªát ƒë·ªô kho·∫£ng 30 ƒë·ªô C
                r"(nhi·ªát ƒë·ªô|n√≥ng|l·∫°nh) .*? (\d+)? .*?",
                "temperature"
            ),
            (# vd: nhi·ªát ƒë·ªô 30 ƒë·ªô C
                r"(nhi·ªát ƒë·ªô|n√≥ng|l·∫°nh) (\d+)? .*?",
                "temperature"
            ),
            (# vd: nhi·ªát ƒë·ªô cao/th·∫•p
                r"(nhi·ªát ƒë·ªô|n√≥ng|l·∫°nh) .*?",
                "temperature"
            ),
            (
                r"(n√≥ng|l·∫°nh)",
                "temperature"
            ),
            # ƒê·ªô ·∫©m
            (# vd: ƒë·ªô ·∫©m kho·∫£ng 70%
                r"(ƒë·ªô ·∫©m|n·ªìm|kh√¥) .*? (\d+)?",
                "humidity"
            ),
            (# vd: ƒë·ªô ·∫©m 70%
                r"(ƒë·ªô ·∫©m|n·ªìm|kh√¥) (\d+)? .*?",
                "humidity"
            ),
            (# vd: ƒë·ªô ·∫©m cao/th·∫•p/kh√¥/·∫©m/√≠t/nhi·ªÅu
                r"(ƒë·ªô ·∫©m|n·ªìm|kh√¥) .*?",
                "humidity"
            ),
            (
                r"(·∫©m|n·ªìm|kh√¥)",
                "humidity"
            ),
            # √Ånh s√°ng
            (
                r"(s√°ng|t·ªëi)",
                "light"
            ),
            # Qu·∫°t
            (# vd: m·ª©c kho·∫£ng 70%
                r"(m·ª©c|t·ªëc ƒë·ªô|quay) .*? (\d+)?",
                "fan"
            ),
            (# vd: m·ª©c 70%
                r"(m·ª©c|t·ªëc ƒë·ªô|quay) (\d+)? .*?",
                "fan"
            ),
            (# vd: m·ª©c 1/2/3
                r"(m·ª©c|t·ªëc ƒë·ªô) (\d+)?",
                "fan"
            ),
            (# vd: m·ª©c cao/th·∫•p/v·ª´a
                r"(m·ª©c|t·ªëc ƒë·ªô|quay) .*?",
                "fan"
            ),
            (
                r"(nhanh|m·∫°nh|cao|ch·∫≠m|y·∫øu|th·∫•p|v·ª´a|th∆∞·ªùng)",
                "fan"
            ),
            # Th·ªùi gian
            (
                r"(sau)\s*"
                r"(?:(?P<hour>\d+)\s*(gi·ªù|h|g)\s*)?"
                r"(?:(?P<minute>\d+)\s*(ph√∫t|p|m)\s*)?"
                r"(?:(?P<second>\d+)\s*(gi√¢y|s))?",
                "time"
            )
        ]

        for pattern, sensor in patterns:
            match = re.search(pattern, sentence, re.IGNORECASE)
            # print(pattern)
            if match:
                val = None
                unit = ""
                op = "="
                if any(kw in sentence for kw in ["tr√™n", "n√≥ng", "nhi·ªÅu h∆°n", "·∫©m", "n·ªìm", "cao"]):
                    op = ">"
                    if "ƒë·ªô ·∫©m" in sentence and not any(kw in sentence for kw in ["tr√™n", "nhi·ªÅu h∆°n", "n·ªìm", "cao"]):
                        op = "="
                elif any(kw in sentence for kw in ["d∆∞·ªõi", "l·∫°nh", "√≠t h∆°n", "kh√¥", "th·∫•p"]):
                    op = "<"
                print(f"match: {match.groups()}")
                if sensor == "time":
                    unit = "seconds"
                    hour = int(match.group("hour")) if match.group("hour") else 0
                    minute = int(match.group("minute")) if match.group("minute") else 0
                    second = int(match.group("second")) if match.group("second") else 0
                    val = hour * 3600 + minute * 60 + second
                elif sensor == "temperature":
                    unit = "¬∞C"
                    if len(match.groups()) > 1:
                        if match.group(2):
                            op = "="
                            val = int(match.group(2))
                            if any(kw in sentence for kw in ["ƒë·ªô k", "¬∞k", "¬∞ka", "ƒë·ªô ka", "ƒë·ªô ca", "¬∞ca"]) and "ƒë·ªô kho·∫£ng" not in sentence:
                                val -= 273
                    elif any(kw in sentence for kw in ["n√≥ng", "cao"]):
                        val = 30
                    elif any(kw in sentence for kw in ["l·∫°nh", "th·∫•p"]):
                        val = 20
                elif sensor == "humidity":
                    unit = "%"
                    if len(match.groups()) > 1:
                        if match.group(2):
                            op = "="
                            val = int(match.group(2))
                    elif any(kw in sentence for kw in ["kh√¥", "th·∫•p", "√≠t"]):
                        val = 30
                    elif "n·ªìm" in sentence:
                        val = 90
                    elif any(kw in sentence for kw in ["cao", "nhi·ªÅu"]):
                        val = 70
                    elif "·∫©m" in sentence and "ƒë·ªô ·∫©m" not in sentence:
                        val = 70
                elif sensor == "light":
                    unit = "lux"
                    if "t·ªëi" in sentence:
                        op = "<"
                        val = 20
                    elif "s√°ng" in sentence:
                        op = ">"
                        val = 30
                elif sensor == "fan":
                    unit = "%"
                    if len(match.groups()) > 1:
                        if match.group(2):
                            op = "="
                            val = int(match.group(2))
                            if val == 1:# 1 l√† m·ª©c th·∫•p nh·∫•t
                                val = 30
                            elif val == 2:
                                val = 70
                            elif val == 3:
                                val = 100
                    elif any(kw in sentence for kw in ["nhanh", "m·∫°nh", "cao"]):
                        val = 100
                    elif any(kw in sentence for kw in ["ch·∫≠m", "y·∫øu", "th·∫•p"]):

                        val = 30
                    elif any(kw in sentence for kw in ["v·ª´a", "th∆∞·ªùng"]):

                        val = 70
                return {
                    "sensor": sensor,
                    "op": op,
                    "value": val,
                    "unit": unit
                }

        return None

    async def nlp_pipeline(self, sentence: str) -> dict:
        await self.init_embeddings(intent_templates=intent_templates)
        condition = self.extract_numeric_condition(sentence)
        sentence_wo_condition = re.sub(r"khi .*|n·∫øu .*|l√∫c .*|khi tr·ªùi .*|n·∫øu tr·ªùi .*|l√∫c tr·ªùi .*|sau .*", "", sentence).strip()

        emb = (await self.get_sentence_embedding(sentence_wo_condition)).unsqueeze(0)
        sims = {}
        for template, template_emb in self.template_embeddings.items():
            template_emb = template_emb.unsqueeze(0)
            sim = cosine_similarity(emb, template_emb)[0][0]
            sims[template] = sim
        best_template = max(sims, key=sims.get)

        return {
            "sentence": sentence,
            "intent": intent_templates[best_template],
            "matched_template": best_template,
            "similarity": float(sims[best_template]),
            "condition": condition
        }

voice_service = VoiceRecordingService()